{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekler = {\n",
    "    \"lak\": 0,\n",
    "    \"nın\": 1,\n",
    "    \"siniz\": 2,\n",
    "    \"ış\": 3,\n",
    "    \"ala\": 4,\n",
    "    \"mış\": 5,\n",
    "    \"ler\": 6,\n",
    "    \"de\": 7,\n",
    "    \"deki\": 8,\n",
    "    \"ka\": 9,\n",
    "    \"dür\": 10,\n",
    "    \"amak\": 11,\n",
    "    \"el\": 12,\n",
    "    \"cuk\": 13,\n",
    "    \"ır\": 14,\n",
    "    \"deş\": 15,\n",
    "    \"gıç\": 16,\n",
    "    \"teş\": 17,\n",
    "    \"eç\": 18,\n",
    "    \"ça\": 19,\n",
    "    \"ma\": 20,\n",
    "    \"imiz\": 21,\n",
    "    \"çıl\": 22,\n",
    "    \"enek\": 23,\n",
    "    \"gaç\": 24,\n",
    "    \"guç\": 25,\n",
    "    \"şer\": 26,\n",
    "    \"ga\": 27,\n",
    "    \"müş\": 28,\n",
    "    \"mek\": 29,\n",
    "    \"layın\": 30,\n",
    "    \"dır\": 31,\n",
    "    \"tan\": 32,\n",
    "    \"li\": 33,\n",
    "    \"ıntı\": 34,\n",
    "    \"anak\": 35,\n",
    "    \"y\": 36,\n",
    "    \"tı\": 37,\n",
    "    \"le\": 38,\n",
    "    \"mede\": 39,\n",
    "    \"nün\": 40,\n",
    "    \"kan\": 41,\n",
    "    \"yecek\": 42,\n",
    "    \"lü\": 43,\n",
    "    \"tır\": 44,\n",
    "    \"cul\": 45,\n",
    "    \"rek\": 46,\n",
    "    \"suz\": 47,\n",
    "    \"ncu\": 48,\n",
    "    \"kıl\": 49,\n",
    "    \"ecek\": 50,\n",
    "    \"mekte\": 51,\n",
    "    \"cik\": 52,\n",
    "    \"ce\": 53,\n",
    "    \"kur\": 54,\n",
    "    \"acak\": 55,\n",
    "    \"tür\": 56,\n",
    "    \"mık\": 57,\n",
    "    \"muk\": 58,\n",
    "    \"mu\": 59,\n",
    "    \"gül\": 60,\n",
    "    \"te\": 61,\n",
    "    \"çü\": 62,\n",
    "    \"meç\": 63,\n",
    "    \"nci\": 64,\n",
    "    \"sel\": 65,\n",
    "    \"ydi\": 66,\n",
    "    \"şin\": 67,\n",
    "    \"rak\": 68,\n",
    "    \"tü\": 69,\n",
    "    \"me\": 70,\n",
    "    \"ti\": 71,\n",
    "    \"leyin\": 72,\n",
    "    \"sı\": 73,\n",
    "    \"sal\": 74,\n",
    "    \"tu\": 75,\n",
    "    \"muş\": 76,\n",
    "    \"leri\": 77,\n",
    "    \"gı\": 78,\n",
    "    \"cü\": 79,\n",
    "    \"ek\": 80,\n",
    "    \"ar\": 81,\n",
    "    \"eceğ\": 82,\n",
    "    \"çuk\": 83,\n",
    "    \"ak\": 84,\n",
    "    \"dü\": 85,\n",
    "    \"den\": 86,\n",
    "    \"çı\": 87,\n",
    "    \"an\": 88,\n",
    "    \"alak\": 89,\n",
    "    \"ncı\": 90,\n",
    "    \"kür\": 91,\n",
    "    \"cu\": 92,\n",
    "    \"mi\": 93,\n",
    "    \"dir\": 94,\n",
    "    \"aç\": 95,\n",
    "    \"t\": 96,\n",
    "    \"cı\": 97,\n",
    "    \"geç\": 98,\n",
    "    \"cıl\": 99,\n",
    "    \"ca\": 100,\n",
    "    \"iniz\": 101,\n",
    "    \"miş\": 102,\n",
    "    \"ı\": 103,\n",
    "    \"da\": 104,\n",
    "    \"k\": 105,\n",
    "    \"ün\": 106,\n",
    "    \"mik\": 107,\n",
    "    \"l\": 108,\n",
    "    \"al\": 109,\n",
    "    \"çük\": 110,\n",
    "    \"luk\": 111,\n",
    "    \"dan\": 112,\n",
    "    \"dirler\": 113,\n",
    "    \"lik\": 114,\n",
    "    \"sek\": 115,\n",
    "    \"iz\": 116,\n",
    "    \"kir\": 117,\n",
    "    \"yse\": 118,\n",
    "    \"p\": 119,\n",
    "    \"cül\": 120,\n",
    "    \"cileyin\": 121,\n",
    "    \"mü\": 122,\n",
    "    \"taş\": 123,\n",
    "    \"çil\": 124,\n",
    "    \"u\": 125,\n",
    "    \"ımsa\": 126,\n",
    "    \"kır\": 127,\n",
    "    \"si\": 128,\n",
    "    \"r\": 129,\n",
    "    \"n\": 130,\n",
    "    \"sü\": 131,\n",
    "    \"lı\": 132,\n",
    "    \"m\": 133,\n",
    "    \"makta\": 134,\n",
    "    \"man\": 135,\n",
    "    \"üncü\": 136,\n",
    "    \"nç\": 137,\n",
    "    \"lık\": 138,\n",
    "    \"dı\": 139,\n",
    "    \"la\": 140,\n",
    "    \"mece\": 141,\n",
    "    \"ten\": 142,\n",
    "    \"sin\": 143,\n",
    "    \"ele\": 144,\n",
    "    \"ın\": 145,\n",
    "    \"sa\": 146,\n",
    "    \"ayım\": 147,\n",
    "    \"çi\": 148,\n",
    "    \"eğen\": 149,\n",
    "    \"ge\": 150,\n",
    "    \"msi\": 151,\n",
    "    \"tur\": 152,\n",
    "    \"ken\": 153,\n",
    "    \"lek\": 154,\n",
    "    \"mse\": 155,\n",
    "    \"lar\": 156,\n",
    "    \"tir\": 157,\n",
    "    \"malı\": 158,\n",
    "    \"lu\": 159,\n",
    "    \"sız\": 160,\n",
    "    \"i\": 161,\n",
    "    \"süz\": 162,\n",
    "    \"se\": 163,\n",
    "    \"msı\": 164,\n",
    "    \"a\": 165,\n",
    "    \"mtırak\": 166,\n",
    "    \"daş\": 167,\n",
    "    \"ncü\": 168,\n",
    "    \"msu\": 169,\n",
    "    \"e\": 170,\n",
    "    \"çık\": 171,\n",
    "    \"men\": 172,\n",
    "    \"ç\": 173,\n",
    "    \"meli\": 174,\n",
    "    \"gil\": 175,\n",
    "    \"çul\": 176,\n",
    "    \"cil\": 177,\n",
    "    \"emek\": 178,\n",
    "    \"maca\": 179,\n",
    "    \"z\": 180,\n",
    "    \"sak\": 181,\n",
    "    \"du\": 182,\n",
    "    \"acağ\": 183,\n",
    "    \"kil\": 184,\n",
    "    \"di\": 185,\n",
    "    \"ş\": 186,\n",
    "    \"msa\": 187,\n",
    "    \"en\": 188,\n",
    "    \"ağan\": 189,\n",
    "    \"mak\": 190,\n",
    "    \"ıcı\": 191,\n",
    "    \"siz\": 192,\n",
    "    \"şar\": 193,\n",
    "    \"elek\": 194,\n",
    "    \"giç\": 195,\n",
    "    \"ki\": 196,\n",
    "    \"yacak\": 197,\n",
    "    \"çe\": 198,\n",
    "    \"şın\": 199,\n",
    "    \"kaç\": 200,\n",
    "    \"maç\": 201,\n",
    "    \"in\": 202,\n",
    "    \"ü\": 203,\n",
    "    \"nin\": 204,\n",
    "    \"ık\": 205,\n",
    "    \"kek\": 206,\n",
    "    \"cük\": 207,\n",
    "    \"im\": 208,\n",
    "    \"laş\": 209,\n",
    "    \"yor\": 210,\n",
    "    \"mı\": 211,\n",
    "    \"ım\": 212,\n",
    "    \"su\": 213,\n",
    "    \"lük\": 214,\n",
    "    \"çu\": 215,\n",
    "    \"dur\": 216,\n",
    "    \"un\": 217,\n",
    "    \"ci\": 218,\n",
    "    \"ymiş\": 219,\n",
    "    \"er\": 220,\n",
    "    \"cık\": 221,\n",
    "    \"çik\": 222,\n",
    "    \"ta\": 223,\n",
    "    \"nun\": 224\n",
    "}\n",
    "\n",
    "ekler = ekler.keys()\n",
    "\n",
    "len(ekler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TURKISH_SUFFIXES = [\n",
    "    \"lar\", \"ler\",\n",
    "    # Common case endings\n",
    "    \"ı\", \"i\", \"u\", \"ü\",\n",
    "    \"yı\", \"yi\", \"yu\", \"yü\",\n",
    "    \"a\", \"e\",\n",
    "    \"ya\", \"ye\",\n",
    "    \"da\", \"de\", \"ta\", \"te\",\n",
    "    \"dan\", \"den\", \"tan\", \"ten\",\n",
    "    # Possessive\n",
    "    \"ım\", \"im\", \"um\", \"üm\",\n",
    "    \"nın\", \"nin\", \"nun\", \"nün\",\n",
    "    \"ımız\", \"imiz\", \"umuz\", \"ümüz\",\n",
    "    \"nız\", \"niz\", \"nuz\", \"nüz\",\n",
    "    # Verb tenses / person\n",
    "    \"m\", \"n\", \"k\", \"ız\", \"iz\", \"uz\", \"üz\",\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\",\n",
    "    \"mış\", \"miş\", \"muş\", \"müş\",\n",
    "    \"acak\", \"ecek\",\n",
    "    \"ar\", \"er\",\n",
    "    # Some derivational\n",
    "    \"lık\", \"lik\", \"luk\", \"lük\",\n",
    "    \"cı\", \"ci\", \"cu\", \"cü\",\n",
    "    \"çı\", \"çi\", \"çu\", \"çü\",\n",
    "    \"laş\", \"leş\", \"laşma\", \"leşme\",\n",
    "    \"ma\", \"me\", \"ış\", \"iş\", \"uş\", \"üş\",\n",
    "    # ... add more if needed\n",
    "]\n",
    "\n",
    "TURKISH_SUFFIXES = set(TURKISH_SUFFIXES)\n",
    "for ek in ekler:\n",
    "    TURKISH_SUFFIXES.add(ek)\n",
    "\n",
    "len(TURKISH_SUFFIXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCT9yiO0M2aIuGu0QENQ3EySy-4gqv7hTE\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21756"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"all_roots.json\") as f:\n",
    "    all_roots = json.load(f)\n",
    "\n",
    "len(all_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create chunks of 500 roots\n",
    "chunk_size = 500\n",
    "\n",
    "chunks = [all_roots[i:i + chunk_size] for i in range(0, len(all_roots), chunk_size)]\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roots_from_gemini(words_chunk, suffixes):\n",
    "  system_prompt = f\"\"\"\n",
    "    Sen bir Türkçe dil kök analizi yapan uzman bir yardımcı araçsın. Görevin, verilen kelimelerden yalnızca Türkçe olanların köklerini bulmaktır. \n",
    "    Kök bulma işlemini yaparken şu kurallara dikkat et:\n",
    "\n",
    "    1. **Türkçe ekleri çıkararak yalnızca kelimenin kökünü bul**. Yapım ve çekim eklerini tamamen kaldır.\n",
    "    2. Türkçe'de yaygın kullanılan yabancı kökenli kelimeleri Türkçe kabul edebilirsin (örneğin: \"tren\", \"televizyon\").\n",
    "    3. Türkçe olmayan kelimeleri tamamen görmezden gel ve çıktıya dahil etme.\n",
    "    4. Kısaltmaları olduğu gibi bırak, uzun hallerini yazma veya değiştirme.\n",
    "    5. Çıktıyı yalnızca JSON formatında bir liste olarak ver. Her kök yalnızca bir kez yer almalıdır.\n",
    "\n",
    "    ### Ekler:\n",
    "    Türkçe'deki yapım ve çekim ekleri şunlardır:\n",
    "    {suffixes}\n",
    "\n",
    "    Örnek çıktı formatı:\n",
    "    [\n",
    "      \"kök1\",\n",
    "      \"kök2\",\n",
    "      \"kök3\"\n",
    "    ]\n",
    "\n",
    "    Aşağıdaki kelimelerin köklerini bul ve yalnızca JSON formatında bir liste ver. Eğer verilen kelimelerin hiçbiri Türkçe değilse, JSON formatında boş bir liste döndür:\n",
    "    []\n",
    "    \"\"\"\n",
    "\n",
    "    # Kullanıcı promptu\n",
    "  user_prompt = (\n",
    "        f\"Aşağıdaki kelimelerin sadece Türkçe olanlarının Türkçe köklerini listele:\\n\\n\"\n",
    "        f\"{', '.join(words_chunk)}\\n\\n\"\n",
    "        f\"Lütfen başka hiçbir şey yazma ve sadece JSON formatında cevap ver.\"\n",
    "    )\n",
    "  \n",
    "  response = model.generate_content(system_prompt + user_prompt)\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 done in 7.387204170227051 seconds\n",
      "Chunk 1 done in 7.558929920196533 seconds\n",
      "Chunk 2 done in 6.348809242248535 seconds\n",
      "Chunk 3 done in 7.778314113616943 seconds\n",
      "Chunk 4 done in 7.800414085388184 seconds\n",
      "Chunk 5 done in 7.48562216758728 seconds\n",
      "Chunk 6 done in 6.488317966461182 seconds\n",
      "Chunk 7 done in 2.5422561168670654 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "  start_time = time.time()\n",
    "  response = get_roots_from_gemini(chunk, TURKISH_SUFFIXES)\n",
    "  with open(f\"gemini_roots/output_{i}.json\", \"w\") as f:\n",
    "    f.write(response)\n",
    "  print(f\"Chunk {i} done in {time.time() - start_time} seconds\")\n",
    "  time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "all_files = os.listdir(\"gemini_roots\")\n",
    "\n",
    "all_roots = set()\n",
    "\n",
    "for file in all_files:\n",
    "  with open(f\"gemini_roots/{file}\") as f:\n",
    "    roots = json.load(f)\n",
    "    all_roots.update(roots)\n",
    "\n",
    "len(all_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20941"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read kokler5.txt\n",
    "with open(\"kokler5.txt\") as f:\n",
    "    kokler = f.readlines()\n",
    "\n",
    "kokler = [kok.strip() for kok in kokler]\n",
    "\n",
    "len(kokler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_roots.txt utf-8\n",
    "with open(\"combined_all_roots.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for root in all_roots:\n",
    "        f.write(root + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21756"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_roots.update(kokler)\n",
    "\n",
    "with open(\"all_roots.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(list(all_roots), f, ensure_ascii=False)\n",
    "\n",
    "len(all_roots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
